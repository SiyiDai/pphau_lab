{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3af86592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyrealsense2.pyrealsense2.pipeline_profile object at 0x0000017310D578B0>\n",
      "depth_profile <pyrealsense2.video_stream_profile: Depth(0) 848x480 @ 30fps Z16>\n",
      "color_profile <pyrealsense2.video_stream_profile: Color(0) 640x480 @ 30fps RGB8>\n",
      "[ 848x480  p[426.785 234.17]  f[419.127 419.127]  Brown Conrady [0 0 0 0 0] ]\n",
      "848 480\n"
     ]
    }
   ],
   "source": [
    "#####################################################\n",
    "##               Read bag from file                ##\n",
    "#####################################################\n",
    "\n",
    "\n",
    "# First import library\n",
    "import pyrealsense2 as rs\n",
    "# Import Numpy for easy array manipulation\n",
    "import numpy as np\n",
    "# Import OpenCV for easy image rendering\n",
    "import cv2\n",
    "# Import argparse for command-line options\n",
    "import argparse\n",
    "# Import os.path for file path manipulation\n",
    "import os.path\n",
    "\n",
    "# Read from Stereo Module\n",
    "# description=\"Read recorded bag file and display depth stream in jet colormap.\n",
    "#              Remember to change the stream fps and format to match the recorded.\"\n",
    "\n",
    "\n",
    "bag_input = '20220405_220626.bag'\n",
    "\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = rs.pipeline()\n",
    "\n",
    "# Create a config object\n",
    "config = rs.config()\n",
    "\n",
    "# Tell config that we will use a recorded device from file to be used by the pipeline through playback.\n",
    "rs.config.enable_device_from_file(config, bag_input)\n",
    "\n",
    "# Configure the pipeline to stream the depth stream\n",
    "# Change this parameters according to the recorded bag file resolution\n",
    "config.enable_stream(rs.stream.depth,848, 480,rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color,640, 480,rs.format.rgb8, 30)\n",
    "\n",
    "# Start streaming from file\n",
    "pipeline.start(config)\n",
    "\n",
    "# Create opencv window to render image in\n",
    "# cv2.namedWindow(\"Depth Stream\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# Create colorizer object\n",
    "colorizer = rs.colorizer()\n",
    "\n",
    "# Streaming loop\n",
    "# while True:\n",
    "#     # Get frameset of depth\n",
    "#     frames = pipeline.wait_for_frames()\n",
    "\n",
    "#     # Get depth frame\n",
    "#     depth_frame = frames.get_depth_frame()\n",
    "\n",
    "#     # Colorize depth frame to jet colormap\n",
    "#     depth_color_frame = colorizer.colorize(depth_frame)\n",
    "\n",
    "#     # Convert depth_frame to numpy array to render image in opencv\n",
    "#     depth_color_image = np.asanyarray(depth_color_frame.get_data())\n",
    "\n",
    "#     # Render image in opencv window\n",
    "#     cv2.imshow(\"Depth Stream\", depth_color_image)\n",
    "#     key = cv2.waitKey(1)\n",
    "#     # if pressed escape exit program\n",
    "#     if key == 27:\n",
    "#         cv2.destroyAllWindows()\n",
    "#         break\n",
    "\n",
    "profile = pipeline.get_active_profile()\n",
    "print(profile)\n",
    "depth_profile = rs.video_stream_profile(profile.get_stream(rs.stream.depth))\n",
    "print(\"depth_profile\",depth_profile)\n",
    "color_profile = rs.video_stream_profile(profile.get_stream(rs.stream.color))\n",
    "print(\"color_profile\", color_profile)\n",
    "depth_intrinsics = depth_profile.get_intrinsics()\n",
    "print(depth_intrinsics)\n",
    "w, h = depth_intrinsics.width, depth_intrinsics.height\n",
    "print(w,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cfc17264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Object Twin (workload 3 students):\n",
    "# In this exercise, we will load a realsense-viewer rosbag recording, then use opencv and pyrender to create a twin of a moving checkerboard.\n",
    "\n",
    "# Loading color and depth data:\n",
    "# Use pyrealsense2 to read the bagfile and acquire color, depth, aligned depth to color, color camera intrinsics, depth camera intrinsics. (Show the images in a loop using cv2.imshow)\n",
    "#\n",
    "# Checkerboard detection and tracking:\n",
    "# The checkerboard has a 6x9 pattern where each square has an edge length of 4 cm.\n",
    "# Using opencv we want Find its corners (use cv2.findChessboardCorners, and cv2.cornersSubPix). then use cv2.drawChessboardCorners to overlay the detections on the colored image\n",
    "# From the previous step, you will have 2D/3D correspondences for the corners. Use cv2.solvePnP to estimate the object to camera translation and rotation vectors.\n",
    "# Extra: Use opencv drawing utils and perspective projection function to draw a 3D axis, and a cropping mask for the board. Useful functions here could be cv2.line,cv2.projectPoints,cv2.fillPoly.\n",
    "#\n",
    "# Modeling the checkerboard in pyrender:\n",
    "# Using pyrender create a scene with camera and a Box mesh corresponding to the checkerboard.\n",
    "# Notes:\n",
    "# You will need to scale the box and shift its center to match the checkerboard 3d coordinate system in opencv\n",
    "# To convert from opencv camera to pyrender camera in you system you may need to rotate your objects by 90 degees around the X-axis (depending on your implementation)\n",
    "#\n",
    "# Visualization:\n",
    "# In the loop, update the mesh pose with the updated pose of the checkerboard\n",
    "# Compare the rendered depth value to the actual algined_depth values we got from realsense.\n",
    "\n",
    "\n",
    "# First import library\n",
    "from matplotlib.pyplot import get\n",
    "import pyrealsense2 as rs\n",
    "# Import Numpy for easy array manipulation\n",
    "import numpy as np\n",
    "# Import OpenCV for easy image rendering\n",
    "import cv2\n",
    "\n",
    "def get_color_images(frames):\n",
    "    # Get color frame\n",
    "    color_frame = frames.get_color_frame()\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "    # Create colorizer object\n",
    "    colorizer = rs.colorizer()\n",
    "    return color_image, colorizer\n",
    "    # return colorizer\n",
    "\n",
    "def get_depth_images(frames, colorizer):\n",
    "    # Get depth frame\n",
    "    depth_frame = frames.get_depth_frame()\n",
    "    # Colorize depth frame to jet colormap\n",
    "    depth_color_frame = colorizer.colorize(depth_frame)\n",
    "    # Convert depth_frame to numpy array to render image in opencv\n",
    "    depth_color_image = np.asanyarray(depth_color_frame.get_data())\n",
    "    depth_image = np.asanyarray(depth_frame.get_data())\n",
    "    return depth_color_image, depth_image\n",
    "\n",
    "def align_images(color_image, colorizer):\n",
    "    # Create alignment primitive with color as its target stream:\n",
    "    align = rs.align(rs.stream.color)\n",
    "    frameset = align.process(frameset)\n",
    "\n",
    "    # Update color and depth frames:\n",
    "    aligned_depth_frame = frameset.get_depth_frame()\n",
    "    colorized_depth = np.asanyarray(colorizer.colorize(aligned_depth_frame).get_data())\n",
    "\n",
    "    # Show the two frames together:\n",
    "    images = np.hstack((color_image, colorized_depth))\n",
    "\n",
    "\n",
    "# def main():\n",
    "\n",
    "rosbag_path = './20220405_220626.bag'\n",
    "# Create pipeline\n",
    "pipeline = rs.pipeline()\n",
    "# Create a config object\n",
    "config = rs.config()\n",
    "# Tell config that we will use a recorded device from file to be used by the pipeline through playback.\n",
    "rs.config.enable_device_from_file(config, rosbag_path)\n",
    "# Configure the pipeline to stream the depth stream\n",
    "# Change this parameters according to the recorded bag file resolution\n",
    "config.enable_stream(rs.stream.depth,848, 480,rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color,640, 480,rs.format.rgb8, 30)\n",
    "# Start streaming from file\n",
    "pipeline.start(config)\n",
    "# # Create opencv window to render image in\n",
    "# cv2.namedWindow(\"Depth Stream\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "# Streaming loop\n",
    "while True:\n",
    "    # Get frameset of depth\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    color_image, colorizer = get_color_images(frames)\n",
    "    depth_color_image, depth_image = get_depth_images(frames, colorizer)\n",
    "\n",
    "    # Render image in opencv window\n",
    "    # align_images(color_image, colorizer)\n",
    "    cv2.imshow(\"Color Stream\", color_image)\n",
    "    cv2.imshow(\"Depth Stream\", depth_color_image)\n",
    "    key = cv2.waitKey(1)\n",
    "    # if pressed escape exit program\n",
    "    if key == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "#     # This code won't run if this file is imported.\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9e53d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
