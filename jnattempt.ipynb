{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import node\n",
    "import pyrealsense2 as rs\n",
    "import pyrender\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kolz14w/pphau/haucode/hw1\n"
     ]
    }
   ],
   "source": [
    "cd ./haucode/hw1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERN_SIZE = (6, 9)\n",
    "\n",
    "\n",
    "def get_color_images(frames):\n",
    "    # Get color frame\n",
    "    color_frame = frames.get_color_frame()\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "    # Create colorizer object\n",
    "    colorizer = rs.colorizer()\n",
    "    return color_image, colorizer\n",
    "\n",
    "\n",
    "def get_depth_images(frames, colorizer):\n",
    "    # Get depth frame\n",
    "    depth_frame = frames.get_depth_frame()\n",
    "    # Colorize depth frame to jet colormap\n",
    "    depth_color_frame = colorizer.colorize(depth_frame)\n",
    "    # Convert depth_frame to numpy array to render image in opencv\n",
    "    depth_color_image = np.asanyarray(depth_color_frame.get_data())\n",
    "    depth_image = np.asanyarray(depth_frame.get_data())\n",
    "    return depth_color_image, depth_image\n",
    "\n",
    "\n",
    "def get_aligned_images(frames, color_image, colorizer):\n",
    "    # Create alignment primitive with color as its target stream:\n",
    "    align = rs.align(rs.stream.color)\n",
    "    aligned_frames = align.process(frames)\n",
    "\n",
    "    # Update color and depth frames:\n",
    "    aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "    colorized_depth = np.asanyarray(\n",
    "        colorizer.colorize(aligned_depth_frame).get_data()\n",
    "    )\n",
    "\n",
    "    # Show the two frames together:\n",
    "    aligned_images = np.hstack((color_image, colorized_depth))\n",
    "\n",
    "    return aligned_images\n",
    "\n",
    "\n",
    "def get_color_camera_intrinsics(profile):\n",
    "    color_profile = rs.video_stream_profile(profile.get_stream(rs.stream.color))\n",
    "    color_intrinsics = color_profile.get_intrinsics()\n",
    "    return color_intrinsics\n",
    "\n",
    "\n",
    "def get_depth_camera_intrinsics(profile):\n",
    "    depth_profile = rs.video_stream_profile(profile.get_stream(rs.stream.depth))\n",
    "    depth_intrinsics = depth_profile.get_intrinsics()\n",
    "    return depth_intrinsics\n",
    "\n",
    "\n",
    "def get_camera_matrix(intrin):\n",
    "    # Get camera metrix from camera intrinsics\n",
    "    camera_matrix = np.array(\n",
    "        [[intrin.fx, 0, intrin.ppx], [0, intrin.fy, intrin.ppy], [0, 0, 1]]\n",
    "    )\n",
    "    return camera_matrix\n",
    "\n",
    "\n",
    "def chessboard_detect(color_image):\n",
    "    # Using opencv we want Find its corners (use cv2.findChessboardCorners,\n",
    "    # and cv2.cornersSubPix). then use cv2.drawChessboardCorners to overlay\n",
    "    # the detections on the colored image\n",
    "    img_show = np.copy(color_image)\n",
    "    res, corners = cv2.findChessboardCorners(img_show, PATTERN_SIZE, None)\n",
    "\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 1e-3)\n",
    "    grayscale_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    cv2.cornerSubPix(grayscale_image, corners, (10, 10), (-1, -1), criteria)\n",
    "    cv2.drawChessboardCorners(img_show, (9, 6), corners, res)\n",
    "    cv2.imshow(\"Chessboard Stream\", img_show)\n",
    "\n",
    "    return corners\n",
    "\n",
    "\n",
    "def translation_calculation(corners, intrin):\n",
    "    # From the previous step, you will have 2D/3D correspondences for the\n",
    "    # corners. Use cv2.solvePnP to estimate the object to camera translation\n",
    "    # and rotation vectors.\n",
    "    camera_matrix = get_camera_matrix(intrin)\n",
    "    dist_coefs = np.asanyarray(intrin.coeffs)\n",
    "\n",
    "    pattern_points = np.zeros((np.prod(PATTERN_SIZE), 3), np.float32)\n",
    "    pattern_points[:, :2] = np.indices(PATTERN_SIZE).T.reshape(-1, 2)\n",
    "\n",
    "    ret, rvec, tvec = cv2.solvePnP(\n",
    "        pattern_points,\n",
    "        corners,\n",
    "        camera_matrix,\n",
    "        dist_coefs,\n",
    "        None,\n",
    "        None,\n",
    "        False,\n",
    "        cv2.SOLVEPNP_ITERATIVE,\n",
    "    )\n",
    "\n",
    "    return rvec, tvec, pattern_points\n",
    "\n",
    "\n",
    "def point_project(\n",
    "    color_image, pattern_points, rvec, tvec, camera_matrix, dist_coefs\n",
    "):\n",
    "    # Extra: Use opencv drawing utils and perspective projection function to\n",
    "    # draw a 3D axis, and a cropping mask for the board. Useful functions here\n",
    "    # could be cv2.line,cv2.projectPoints,cv2.fillPoly.\n",
    "    img_points, _ = cv2.projectPoints(\n",
    "        pattern_points, rvec, tvec, camera_matrix, dist_coefs\n",
    "    )\n",
    "    for c in img_points.squeeze():\n",
    "        cv2.circle(color_image, tuple(c), 10, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"points\", color_image)\n",
    "    cv2.waitKey()\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scene(points_3d, homo_trans):\n",
    "    flag = False\n",
    "    if flag == False:\n",
    "        if homo_trans.shape == [4,4]:\n",
    "            # TODO: reconstruct the points_3d, add rows and columns to the edge with 4cm\n",
    "            mesh = pyrender.Mesh.from_points(points_3d)\n",
    "            scene = pyrender.Scene()\n",
    "            node = pyrender.Node(mesh=mesh, matrix = homo_trans)\n",
    "            scene.add_node(node)\n",
    "            v = pyrender.Viewer(scene, run_in_thread=True)\n",
    "            flag = True\n",
    "        else:\n",
    "            mesh = pyrender.Mesh.from_points(points_3d)\n",
    "            scene = pyrender.Scene()\n",
    "            node = pyrender.Node(mesh=mesh, matrix=np.eye(4))\n",
    "            scene.add_node(node)\n",
    "            v = pyrender.Viewer(scene, run_in_thread=True)\n",
    "            flag = True\n",
    "            \n",
    "    return v, node, scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosbag_path = \"./Homework/HW1-2-data/20220405_220626.bag\"\n",
    "# Create a config object\n",
    "config = rs.config()\n",
    "# Tell config that we will use a recorded device from file to be used by the pipeline through playback.\n",
    "rs.config.enable_device_from_file(config, rosbag_path)\n",
    "# Configure the pipeline to stream the depth stream\n",
    "# Change this parameters according to the recorded bag file resolution\n",
    "config.enable_stream(rs.stream.depth, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, rs.format.rgb8, 30)\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = rs.pipeline()\n",
    "# Start streaming from file\n",
    "pipeline.start(config)\n",
    "profile = pipeline.get_active_profile()\n",
    "color_intrin = get_color_camera_intrinsics(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mesh_creation(obj_points, homo_trans):\n",
    "    import trimesh\n",
    "    sm = trimesh.creation.uv_sphere(radius=1)\n",
    "    sm.visual.vertex_colors = [1, 0, 0]\n",
    "    tfs = np.tile(homo_trans, (len(obj_points), 1, 1))\n",
    "    tfs[:,:3,3] = obj_points\n",
    "    m = pyrender.Mesh.from_trimesh(sm, poses = tfs)\n",
    "    return m\n",
    "#    scene = pyrender.Scene()\n",
    "#    scene.add(m)\n",
    "#    pyrender.Viewer(scene, use_raymond_lighting = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-736a2bb6cc12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcolor_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_color_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdepth_color_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_depth_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0maligned_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_aligned_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mcorners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchessboard_detect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     rvec, tvec, pattern_points = translation_calculation(\n",
      "\u001b[0;32m<ipython-input-3-f6e4f7d68466>\u001b[0m in \u001b[0;36mget_aligned_images\u001b[0;34m(frames, color_image, colorizer)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Create alignment primitive with color as its target stream:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0malign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0maligned_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Update color and depth frames:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "flag = False\n",
    "\n",
    "while True:\n",
    "    # Get frameset of depth\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    color_image, colorizer = get_color_images(frames)\n",
    "    depth_color_image, depth_image = get_depth_images(frames, colorizer)\n",
    "    aligned_images = get_aligned_images(frames, color_image, colorizer)\n",
    "    corners = chessboard_detect(color_image)\n",
    "    rvec, tvec, pattern_points = translation_calculation(\n",
    "        corners, intrin=color_intrin)\n",
    "    ## Generate homogenous transformation matrix\n",
    "    \n",
    "    rmat = cv2.Rodrigues(rvec)[0]\n",
    "    homo_trans = np.hstack([rmat, tvec])\n",
    "    base = [0, 0, 0, 1]\n",
    "    homo_trans = np.vstack([homo_trans, base]) \n",
    "    # Generate Trimesh based on object points and homogenous tfs matrix\n",
    "    \n",
    "    m = mesh_creation(pattern_points, homo_trans)\n",
    "        \n",
    "    if flag == False:\n",
    "        scene = pyrender.Scene()\n",
    "        # v = pyrender.Viewer(scene,run_in_thread=True)\n",
    "        camera_pose = np.eye(4)\n",
    "        # camera_pose[:3,3] = [0.3, 0.0, 0.35]\n",
    "        # camera_pose[:3,:3] = Rotation.from_euler('xyz', [45, 0, 90],degrees=True).as_matrix()\n",
    "        camera = pyrender.IntrinsicsCamera(fx=color_intrin.fx, fy=color_intrin.fy,\n",
    "                                           cx=color_intrin.ppx, cy=color_intrin.ppy)\n",
    "        chessboard = pyrender.Node(mesh = m, matrix = homo_trans)\n",
    "        scene.add_node(chessboard)\n",
    "        # scene.add(camera, pose=camera_pose)\n",
    "        v = pyrender.Viewer(scene,run_in_thread=True)\n",
    "        flag = True\n",
    "        print('1')\n",
    "    else:\n",
    "        scene.set_pose(chessboard, pose = homo_trans)\n",
    "        print('0')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
